{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256d3948",
   "metadata": {},
   "source": [
    "<img src=\"https://www.rp.edu.sg/images/default-source/default-album/rp-logo.png\" width=\"200\" alt=\"Republic Polytechnic\"/>\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/koayst-rplesson/SDGAI_LLMforGenAIApp_Labs/blob/main/L09/L09.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e80164-bf97-4962-b425-7864a154dcaf",
   "metadata": {},
   "source": [
    "# Setup and Installation\n",
    "\n",
    "You can run this Jupyter notebook either on your local machine or run it at Google Colab.\n",
    "\n",
    "* For local machine, it is recommended to install Anaconda and create a new development environment called `c3669c`.\n",
    "* Pip/Conda install the libraries stated below when necessary.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6f4c2-8506-415c-a295-041ee40d9eda",
   "metadata": {},
   "source": [
    "# <font color='red'>ATTENTION</font>\n",
    "\n",
    "## Google Colab\n",
    "- If you are running this code in Google Colab, **DO NOT** store the API Key in a text file and load the key later from Google Drive. This is insecure and will expose the key.\n",
    "- **DO NOT** hard code the API Key directly in the Python code, even though it might seem convenient for quick development.\n",
    "- You need to enter the API key at python code `getpass.getpass()` when ask.\n",
    "\n",
    "## Local Environment/Laptop\n",
    "- If you are running this code locally in your laptop, you can create a env.txt and store the API key there.\n",
    "- Make sure env.txt is in the same directory of this Jupyter notebook.\n",
    "- You need to install `python-dotenv` and run the Python code to load in the API key.\n",
    "\n",
    "---\n",
    "```\n",
    "%pip install python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('env.tx')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "```\n",
    "---\n",
    "\n",
    "## GitHub/GitLab\n",
    "- **DO NOT** `commit` or `push` API Key to services like GitHub or GitLab.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c79ed1d-cc1e-4712-93ce-695496907dd7",
   "metadata": {},
   "source": [
    "# Lesson 09\n",
    "\n",
    "- LangChain is a framework built around LLMs.\n",
    "- Framework offered as a Python or Javascript (Typescript) package.\n",
    "- Use it to build chatbots, Generative Question-Answer (GQA), summarization and much more.\n",
    "- Core idea is to “chain” together different components to create more advanced use cases around LLMs.\n",
    "- Provides developers with a comprehensive set of tools to seamlessly combine multiple prompts working with LLMs effortlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a344c6-9289-4351-9677-8e7f778c7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain\n",
    "%pip install --quiet -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f2767-9f87-48e8-b1b7-c0b952d2cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain        0.3.11\n",
    "# langchain-core   0.3.24\n",
    "# langchain-openai 0.2.12\n",
    "# openai           1.57.2\n",
    "# pydantic         2.10.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7281bdb-a238-4cad-abac-6679aa169ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# setup the OpenAI API Key\n",
    "\n",
    "# get OpenAI API key ready and enter it when ask\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc02a79-8283-4235-b570-c813d51bff91",
   "metadata": {},
   "source": [
    "### A Simple LLM Application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892ce11d-96fc-4aad-b307-0ec50122e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load langchain libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2fe6ff-5fba-46d9-a05d-ec835ce93b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why not a gpt-3.5-turbo-instruct ?\n",
    "# https://github.com/BerriAI/litellm/issues/749\n",
    "# gpt-3.5-turbo-instruct is an openai text completions model and so gets routed to completions not chat completions.\n",
    "\n",
    "# in summary you will notice the patterns:\n",
    "# model name = gpt-3.5-turbo-instruct --> text completion --> OpenAI\n",
    "# model name - gpt-3.5-turbo --> chat completion --> ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    # don't need this if the OpenAI API Key is stored in the environment variable\n",
    "    #openai_api_key=\"sk-proj-xxxxxxxxx\",\n",
    "\n",
    "    #model_name='gpt-3.5-turbo'\n",
    "    model_name='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f524decd-83e2-47ac-a9c0-8ce81fe1946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup message prompt\n",
    "text = \"What date is Singapore National Day?\"\n",
    "messages = [HumanMessage(content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2ebcf8-6c39-432a-b0a5-13eefbfd9ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singapore National Day is celebrated on August 9th each year. It commemorates Singapore's independence from Malaysia, which occurred on that date in 1965.\n"
     ]
    }
   ],
   "source": [
    "# note that Chat Model takes in message objects as input and generate message object as output\n",
    "\n",
    "response = chat_model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324918b-ae6e-49ae-8eb3-edbd8569817d",
   "metadata": {},
   "source": [
    "### A Simple LLM Application With Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53266ed8-b053-4872-8622-a5949dda4154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load langchain libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba721d4-9855-4c15-a188-ff90b396068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise ChatModel with API key\n",
    "chat_model = ChatOpenAI(\n",
    "    model_name='gpt-4o-mini', \n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c572494-7a0a-4df2-a7e1-e7b9a55f1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template takes in raw user input ({input_language} and {output_language}) and \n",
    "# return a prompt that is ready to pass into a language model\n",
    "\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "\n",
    "human_template = \"{text}\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2005be55-3b7f-45d6-bc9e-a7538c7d0b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'aime la programmation.\n"
     ]
    }
   ],
   "source": [
    "# trsnslate English to French\n",
    "\n",
    "messages = chat_prompt.format_messages(\n",
    "    input_language=\"English\", \n",
    "    output_language=\"French\", \n",
    "    text=\"I love programming.\"\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(messages).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da80a83a-d814-4c23-9aa8-9efa33ee7ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我爱编程。\n"
     ]
    }
   ],
   "source": [
    "# translate English to Chinese\n",
    "\n",
    "messages = chat_prompt.format_messages(\n",
    "    input_language=\"English\", \n",
    "    output_language=\"Chinese\", \n",
    "    text=\"I love programming.\"\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(messages).content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7520039-1b31-46ca-96da-f5af86facff2",
   "metadata": {},
   "source": [
    "# Observation\n",
    "\n",
    "- From the two sample codes you just run, you have learned how to create your first simple LLM application. \n",
    "- You learned how to work with language model(s) and how to create a prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed6301b-ede6-4653-879e-8c47cc0b0d2b",
   "metadata": {},
   "source": [
    "## PromptTemplate And LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e694c058-eb8e-4cfa-bf5c-28ebc0e75280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load langchain libraries\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.output_parsers.string import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f05f62e3-cd4c-44a5-8f90-313755229e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4 does not have 'instruct' model\n",
    "# The chat models like gpt-4 and gpt-4-turbo are already instruction-following models.\n",
    "# They are designed to interpret and respond effectively to instructions provided in the conversatio\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-4o-mini',\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d692ef24-ee42-4564-87ba-0002b5b191c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup template \n",
    "\n",
    "human_template = \"Write {lines} sentences about {topic}.\"\n",
    "prompt = ChatPromptTemplate.from_template(human_template)\n",
    "\n",
    "lines_topic_dict = {\n",
    "    \"lines\" : \"3\", \n",
    "    \"topic\": \"Sir Stamford Raffles\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc8889c-e7f3-4096-a4df-14880c1a0bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sir Stamford Raffles was a British statesman and the founder of modern Singapore, establishing the island as a strategic trading post for the British East India Company in 1819. His vision extended beyond commerce; he was also a naturalist and played a significant role in promoting the study of Southeast Asian flora and fauna. Raffles' legacy is marked by his contributions to the region's development, his advocacy for education, and his efforts to preserve local culture and heritage.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 17, 'total_tokens': 110, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-2abe430e-8af3-4d73-835b-b5ad23bfc6ad-0', usage_metadata={'input_tokens': 17, 'output_tokens': 93, 'total_tokens': 110, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without piping to StrOutputParser\n",
    "# StrOutputParser = OutputParser that parses LLMResult into the top likely string\n",
    "\n",
    "lcel_chain_01 = prompt | llm\n",
    "\n",
    "lcel_chain_01.invoke(lines_topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7d3fca9-f12f-4eb8-9e29-1f4fd13f91e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sir Stamford Raffles was a British statesman and the founder of modern Singapore, establishing the island as a key trading post for the British East India Company in 1819. His vision extended beyond commerce; he was also an advocate for education, cultural preservation, and the welfare of local populations. Raffles' contributions to the region have left a lasting legacy, making him a pivotal figure in Southeast Asian history.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipe to StrOutputParesr\n",
    "\n",
    "lcel_chain_02 = prompt | llm | output_parser\n",
    "\n",
    "lcel_chain_02.invoke(lines_topic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b801238-1095-4cac-8605-a110ca15ab0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
