{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1a8db8-15c7-44eb-bb4f-f8ba4d188feb",
   "metadata": {},
   "source": [
    "<img src=\"https://www.rp.edu.sg/images/default-source/default-album/rp-logo.png\" width=\"200\" alt=\"Republic Polytechnic\"/>\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/koayst-rplesson/SDGAI_LLMforGenAIApp_Labs/blob/main/L06/L06.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbeaf1c-5ab7-42e7-b9e7-3fd196c0c598",
   "metadata": {},
   "source": [
    "# Setup and Installation\n",
    "\n",
    "You can run this Jupyter notebook either on your local machine or run it at Google Colab.\n",
    "\n",
    "* For local machine, it is recommended to install Anaconda and create a new development environment called `c3669c`.\n",
    "* Pip/Conda install the libraries stated below when necessary.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f03c6c-0d1f-40b2-8a4d-9f7a6437a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the libraries. Only need to do the installation once. After installation you can comment out the code.\n",
    "\n",
    "!pip install transformers torch\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605cebeb-4149-4a84-b869-8a64e24ebcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Versions Checking\n",
    "\n",
    "# accelerate = 1.1.1\n",
    "# torch = 2.5.1\n",
    "# transformers = 4.46.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ea40ad-4ea4-440c-8ab5-ffd2a15af692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from transformers[torch]) (1.1.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from torch->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\koay_seng_tian\\appdata\\local\\anaconda3\\envs\\c3669c\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dbe607-a2ee-47f0-bf62-9fbecf662032",
   "metadata": {},
   "source": [
    "## Permission\n",
    "\n",
    "Set up an account with Huggingface if you don't have an account.\n",
    "\n",
    "Before you continue, you are required to apply for permission to access the Llama-3.2 model(s) if you get the error message as shown below:\n",
    "\n",
    "`Access to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct to ask for access.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228b7c3-35b7-4c6f-8f7e-7ac6f19a5e96",
   "metadata": {},
   "source": [
    "## Huggingface Jupyter Notebook/Lab Login\n",
    "\n",
    "- Login to huggingface.\n",
    "- Go to your account and create an access tokens for this exercise\n",
    "- Go to `Write` tab to create the access token i.e. token name, for example, C3669C\n",
    "- Copy the access token key and put it in a safe place for later use\n",
    "- If you forget your access token key, if you have create a new one\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"huggingface-01.png\">\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"huggingface-02.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c043d9a-5883-4b53-a5da-ddc5e97df179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c297d29156f4f388ecdb462cb7221cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# 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\n",
    "# uncheck `Add token as git credential?`\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b21945-4a3c-4bb3-a2f6-b1fe3047ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380eb068-fbde-4afc-a65a-50e17c51a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3b2372-a8a9-4234-ab95-cdbeebcba7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the padding token if it's not already set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a56e5-a536-40cd-b41f-49f99db8a567",
   "metadata": {},
   "source": [
    "## Prepare your FAQ Dataset\n",
    "\n",
    "A fake dataset is created for the FAQ dataset. Here is a sample dataset for this exercise.\n",
    "\n",
    "### Questions:\n",
    "- Explain quantum computing in simple terms.\n",
    "- What are the benefits of renewable energy?\n",
    "- Describe the process of photosynthesis.\n",
    "- What is the significance of the Renaissance?\n",
    "- How does the human immune system work?\n",
    "\n",
    "### Answers:\n",
    "- Quantum computing uses quantum bits, or qubits, to perform calculations. Unlike classical bits that are either 0 or 1, qubits can exist in multiple states simultaneously, allowing quantum computers to solve certain complex problems faster.\n",
    "- Renewable energy, such as solar and wind, reduces greenhouse gas emissions, decreases air pollution, and conserves natural resources. It also promotes energy independence and sustainability.\n",
    "- Photosynthesis is the process by which green plants use sunlight to make food from carbon dioxide and water. It occurs in the chloroplasts, producing oxygen as a byproduct.\n",
    "- The Renaissance was a cultural movement from the 14th to the 17th century, characterized by a renewed interest in classical art, science, and philosophy. It led to significant advancements in many fields and a shift towards humanism.\n",
    "- The human immune system protects the body from infections and diseases. It consists of physical barriers, immune cells, and proteins that identify and destroy pathogens like bacteria and viruses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07174c27-1132-4cb1-89d4-4ebf3bdcfa19",
   "metadata": {},
   "source": [
    "## Tokenize the Data\n",
    "\n",
    "We need to tokenize the sentences (Questions and Answers) to make them compatible for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b8013d-55fa-401f-8a8e-5e39e4f1cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompts and responses\n",
    "prompts = [\n",
    "    \"Explain quantum computing in simple terms.\",\n",
    "    \"What are the benefits of renewable energy?\",\n",
    "    \"Describe the process of photosynthesis.\",\n",
    "    \"What is the significance of the Renaissance?\",\n",
    "    \"How does the human immune system work?\"\n",
    "]\n",
    "responses = [\n",
    "    \"Quantum computing uses quantum bits, or qubits, to perform calculations. Unlike classical bits that are either 0 or 1, qubits can exist in multiple states simultaneously, allowing quantum computers to solve certain complex problems faster.\",\n",
    "    \"Renewable energy, such as solar and wind, reduces greenhouse gas emissions, decreases air pollution, and conserves natural resources. It also promotes energy independence and sustainability.\",\n",
    "    \"Photosynthesis is the process by which green plants use sunlight to make food from carbon dioxide and water. It occurs in the chloroplasts, producing oxygen as a byproduct.\",\n",
    "    \"The Renaissance was a cultural movement from the 14th to the 17th century, characterized by a renewed interest in classical art, science, and philosophy. It led to significant advancements in many fields and a shift towards humanism.\",\n",
    "    \"The human immune system protects the body from infections and diseases. It consists of physical barriers, immune cells, and proteins that identify and destroy pathogens like bacteria and viruses.\"\n",
    "]\n",
    "\n",
    "# Set a consistent max length\n",
    "max_length = 50\n",
    "\n",
    "# Tokenize prompts and responses\n",
    "tokenized_inputs = tokenizer(prompts, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "tokenized_labels = tokenizer(responses, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Ensure labels' padding tokens are ignored in loss computation\n",
    "tokenized_labels[tokenized_labels == tokenizer.pad_token_id] = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32a5bc-951d-4928-bfc9-0b6d1a3a5277",
   "metadata": {},
   "source": [
    "## Create a Custom Dataset\n",
    "\n",
    "Use PyTorch's `Datset` class to create a dataset for trainging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccf1b53-e76a-4957-818e-4d190e0040bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Create a custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.inputs[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.inputs[\"attention_mask\"][idx],\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = CustomDataset(tokenized_inputs, tokenized_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ea120-f71b-4f53-a30c-27c271579c30",
   "metadata": {},
   "source": [
    "## Configure Training Parameters\n",
    "\n",
    "Setup the training parameters using the `TrainingArguments` class and initialise the `Trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13c370db-5aa5-4b05-b830-7d22ccb54bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "# Data collator to handle padding\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Increase the number of training epochs if necessary\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=3,  # Increase to 5 or more\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658c328-83ec-404f-9a29-68ff967c7f02",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983133de-5f87-45c3-b3f4-72e8259a5799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koay_seng_tian\\AppData\\Local\\anaconda3\\envs\\c3669c\\lib\\site-packages\\transformers\\data\\data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 21:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "try:\n",
    "    trainer.train()\n",
    "except ValueError as e:\n",
    "    print(\"\\nError during training:\")\n",
    "    print(e)\n",
    "\n",
    "# Note:\n",
    "# On laptop: i7-1165G7 @ 2.8GHz, 16.0GB RAM, Windows 11 Enterprise, it took 21mins 40 secs to complete the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7e8e7-d375-4b48-9427-a9b56e311541",
   "metadata": {},
   "source": [
    "## Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b8e82f-2ea6-4dc2-bc65-fe8f01594640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./trained_model\")\n",
    "tokenizer.save_pretrained(\"./trained_model\")\n",
    "\n",
    "print(\"Model and tokenizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595b57f-a0ff-4fc6-aa58-57c02c995908",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Test the newly fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8322a3e-4b48-4176-ad86-3d66d39094ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import textwrap\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee2e66a-dda8-46e6-82ec-5ca5897c22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./trained_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb66de07-7cfe-4456-b43f-84d0a2c88b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and move the model to GPU\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "text_generation = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad9374b-7745-4957-a3e7-6f5d70d636d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text:\n",
      "\n",
      "Describe the process of photosynthesis. plants and green plants. green plants\n",
      "are plants that use sunlight, water, and carbon dioxide to produce their food.\n",
      "plants have leaves that are green and green leaves are the food source for\n",
      "plants. green plants are plants that have leaves that are green.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test the model\n",
    "prompt = \"Describe the process of photosynthesis.\"\n",
    "generated_text = text_generation(prompt, max_new_tokens=50, temperature=0.7, top_p=0.9)[0][\"generated_text\"]\n",
    "\n",
    "# Format the output for better readability\n",
    "wrapped_text = textwrap.fill(generated_text, width=80)\n",
    "\n",
    "print(\"\\nGenerated Text:\\n\")\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e766888-c5ce-4873-95b9-103a6baacc29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
